# -*- coding: utf-8 -*-
"""word_cloud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j8Npe9VvkBiboON8y5WK4_C6dlWNs93y
"""



!pip install opencv-python
import os
os.chdir('/content/drive/My Drive/Hate Speech Detection/Project Codes/')
!pip install profanity-check
from itertools import chain
import wordcloud
from wordcloud import WordCloud, STOPWORDS 
import matplotlib.pyplot as plt 
import pandas as pd 
import profanity_check
from profanity_check import predict, predict_prob


df = pd.read_csv(r"hate_clean.csv", encoding ="latin-1") 
data = df['tweet']
li=['a','e','i','o','u']
print(li)
  
comment_words = ' '
stopwords = set(STOPWORDS)
#print(data) 
  
# iterate through the csv file 
for val in data: 
      
    # typecaste each val to string 
    val = str(val) 
  
    # split the value 
    tokens = val.split()
      
    # Converts each token into lowercase 
    for i in range(len(tokens)): 
        tokens[i] = tokens[i].lower() 
    
    c = "*"
    i=0
    for words in tokens:
      if predict_prob([words])>0.5:
        for ch in words:
          if ch in li:
            words = words.replace(ch,c)
            words=str(words)
            print(words)
      comment_words += words +' '






wordcloud = WordCloud(collocations = False, width = 800, height = 800, 
                      background_color = 'white', regexp = "[a-z*]+", repeat = False, max_words = 100,
                      min_font_size = 10).generate(comment_words)

plt.figure(figsize = (8, 8), facecolor = None) 
plt.imshow(wordcloud,interpolation='bilinear') 
plt.axis("off") 
plt.tight_layout(pad = 0) 
plt.show()